{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPeulvp-meob"
   },
   "source": [
    "**ASSIGNMENT 2 - Classification Empirical Study: Naïve Bayes vs Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "**1. Group Description**\n",
    "\n",
    "Group Number: 10\n",
    "\n",
    "Member Name 1: Xiaoxuan Wang\n",
    "\n",
    "Member Student Number 1: 300133594\n",
    "\n",
    "Member Name 2: Victor Li\n",
    "\n",
    "Member Student Number 2: 300146133"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZTWy1qN2BzY"
   },
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmP1buROhaOx"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8vwHE0G_iOG"
   },
   "source": [
    "**2. Dataset**\n",
    "\n",
    "Chosen dataset: Car dataset\n",
    "\n",
    "The dataset is coming from [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/).\n",
    "It can be retrieved by following [this link](https://archive.ics.uci.edu/dataset/19/car+evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNJyoeCz00Kr"
   },
   "source": [
    "**Read Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrhpM-HwhaOy"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/uOttawa-Collabs/CSI4106-Fall-2023/master/Assignment%202/Car/car.data\"\n",
    "dataframe = pandas.read_csv(url)\n",
    "dataframe.columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ER3-7di7ufy"
   },
   "source": [
    "**3. Familiarize with the classification task and the dataset**\n",
    "\n",
    "***Objective***\n",
    "\n",
    "The objective of this study is to develop a classification model to evaluate cars based on their configurations and parameters. The dataset comprises six discrete (categorical) feature variables: buying price, maintenance price, number of doors, capacity in terms of persons, the size of the luggage boot, and estimated safety of the car. The target variable is the evaluation of the car, categorized into four classes: unacceptable, acceptable, good, and very good.\n",
    "\n",
    "***Applications***\n",
    "\n",
    "1. May assist customers to make informed decisions based on their preferences and constraints, offering valuable insights.\n",
    "2. May assist car dealership to help assist potential buyers in finding cars that align with their requirements, thereby enhancing customer satisfaction and loyalty.\n",
    "\n",
    "***Dataset Characteristics Analysis***\n",
    "\n",
    "****Features****\n",
    "\n",
    "The dataset used for this study contains information on the following six feature variables:\n",
    "* Buying Price (`buying`): Indicates the price range at which the car was purchased.\n",
    "    * Possible values: `vhigh`, `high`, `med`, `low`.\n",
    "* Maintenance Price (`maint`): Represents the maintenance cost of the car.\n",
    "    * Possible values: `vhigh`, `high`, `med`, `low`.\n",
    "* Number of Doors (`doors`): Denotes the number of doors the car has.\n",
    "    * Possible values: `2`, `3`, `4`, `5more`.\n",
    "* Capacity (`persons`): Indicates the maximum number of persons the car can accommodate.\n",
    "    * Possible values: `2`, `4`, `more`.\n",
    "* Luggage Boot Size (`lug_boot`): Represents the size of the luggage boot in the car.\n",
    "    * Possible values: `small`, `med`, `big`.\n",
    "* Estimated Safety (`safety`): Provides an estimation of the safety level of the car.\n",
    "    * Possible values: `low`, `med`, `high`.\n",
    "\n",
    "****Classes****\n",
    "\n",
    "The target variable is Car Evaluation (`class`), which classifies cars into four categories:\n",
    "unacceptable (`unacc`), acceptable (`acc`), good (`good`), and very good (`vgood`).\n",
    "These classes serve as the basis for evaluating the overall desirability of a car.\n",
    "\n",
    "****Training Examples****\n",
    "\n",
    "The dataset contains 1728 training samples in total. No samples have missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Brainstorm about the attributes**\n",
    "\n",
    "* In the automotive sales market, various factors significantly influence purchasing decisions. Aside from intrinsic attributes provided in the dataset, **features**, **second-hand price**, **power**, **brand**, **color**, and **after-sale service** are essential as well.\n",
    "\n",
    "  Among the provided attributes in the dataset, the data related to the **number of doors** appears to be less useful, given its correlation with a car's **capacity**. In typical scenarios, a capacity of 2 necessitates a minimum of 2 doors, while a capacity of 4 often results in 4 doors, with a minimum of 2. The relationship between a car's capacity and its doors is evident: larger capacities generally correspond to a higher number of doors. Although it is conceivable that unconventional door numbers, such as odd numbers, might intrigue some customers, it is unlikely that this singular feature significantly influences purchase decisions.\n",
    "\n",
    "* Based on the diagrams below, it is apparent that each feature exhibits uniformity across all values, mitigating potential biases during model training. Given that all features in this dataset represent discrete values (for instance, the number of persons cannot be fractional), the method of attribute normalization appears inappropriate for this specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "\n",
    "buying_dict = {\"low\": 0, \"med\": 0, \"high\": 0, \"vhigh\": 0}\n",
    "maint_dict = {\"low\": 0, \"med\": 0, \"high\": 0, \"vhigh\": 0}\n",
    "door_dict = {\"2\": 0, \"3\": 0, \"4\": 0, \"5more\": 0}\n",
    "persons_dict = {\"2\": 0, \"4\": 0, \"more\": 0}\n",
    "lug_dict = {\"small\": 0, \"med\": 0, \"big\": 0}\n",
    "safety_dict = {\"low\": 0, \"med\": 0, \"high\": 0}\n",
    "\n",
    "def analyze_data(dataframe, prop, dic):\n",
    "    data = dataframe[prop]\n",
    "    for row in data:\n",
    "        dic[row] += 1\n",
    "    generate_diagram(dic, prop)\n",
    "\n",
    "def generate_diagram(dic: dict, name):\n",
    "    print(dic)\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i in dic.keys():\n",
    "        x_list.append(i)\n",
    "        y_list.append(dic[i])\n",
    "    plot.bar(x_list, y_list)\n",
    "    plot.title(\"Analysis of \" + \" Feature \" + name)\n",
    "    plot.xlabel(\"name\")\n",
    "    plot.ylabel(\"number\")\n",
    "    plot.show()\n",
    "\n",
    "\n",
    "analyze_data(dataframe, \"buying\", buying_dict)\n",
    "analyze_data(dataframe, \"maint\", maint_dict)\n",
    "analyze_data(dataframe, \"doors\", door_dict)\n",
    "analyze_data(dataframe, \"persons\", persons_dict)\n",
    "analyze_data(dataframe, \"lug_boot\", lug_dict)\n",
    "analyze_data(dataframe, \"safety\", safety_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Encode the features**\n",
    "\n",
    "* The data source that was chosen is using discrete variables for all features. It natively fits into the Categorical Naive Bayes Model (`CategoricalNB`). We just need to label them with integers.\n",
    "* For Logistic Regression, one-hot encoding enables the conversion to continuous variables for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "feature_columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]\n",
    "class_column = \"class\"\n",
    "\n",
    "# Performing label encoding for features\n",
    "dataframe_label_feature = pandas.DataFrame().reindex_like(dataframe[feature_columns])\n",
    "label_encoder_dict = {}\n",
    "for column in feature_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    dataframe_label_feature[column] = label_encoder.fit_transform(dataframe[column])\n",
    "    label_encoder_dict[column] = label_encoder\n",
    "\n",
    "# Performing one-hot encoding for features\n",
    "onehot_encoder_feature = OneHotEncoder(sparse_output=False)\n",
    "matrix_onehot_feature = onehot_encoder_feature.fit_transform(dataframe[feature_columns])\n",
    "dataframe_onehot_feature = pandas.DataFrame(\n",
    "    matrix_onehot_feature,\n",
    "    columns=onehot_encoder_feature.get_feature_names_out()\n",
    ")\n",
    "\n",
    "# Performing label encoding for classes\n",
    "label_encoder_class = LabelEncoder()\n",
    "vector_label_class = label_encoder_class.fit_transform(dataframe[class_column])\n",
    "dataframe_label_class = pandas.DataFrame(vector_label_class, columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Define 2 models using default parameters**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "default_naive_bayes_classifier = CategoricalNB()\n",
    "default_logistic_regression_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Train/test/evaluate the 2 models in cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialize KFold Cross Validator***\n",
    "\n",
    "Here we are initializing the `KFold` validator. Explanation of parameters:\n",
    "* `n_splits=4` means we are using 4-fold validation.\n",
    "* `shuffle=True` means data will be shuffled before spliting to batches.\n",
    "* `random_state` is the random seed used for shuffling. Here we are using a fixed number to keep reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "four_fold = KFold(n_splits=4, shuffle=True, random_state=4106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training and Evaluating the Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Utility Functions****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "def train_and_evaluate(model, validator, dataframe_training, series_validating):\n",
    "    micro_precision_scores = []\n",
    "    macro_precision_scores = []\n",
    "    micro_recall_scores = []\n",
    "    macro_recall_scores = []\n",
    "    \n",
    "    X = dataframe_training\n",
    "    y = series_validating\n",
    "\n",
    "    # Split the dataset into training set and testing set with validator\n",
    "    for train_index, test_index in validator.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        # Make predictions ŷ\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        # Calculate precision and recall for micro and macro averages\n",
    "        micro_precision = precision_score(y_test, y_hat, average=\"micro\", zero_division=0)\n",
    "        macro_precision = precision_score(y_test, y_hat, average=\"macro\", zero_division=0)\n",
    "        micro_recall = recall_score(y_test, y_hat, average=\"micro\", zero_division=0)\n",
    "        macro_recall = recall_score(y_test, y_hat, average=\"macro\", zero_division=0)\n",
    "\n",
    "        # Append scores to lists\n",
    "        if micro_precision != 0:\n",
    "            micro_precision_scores.append(micro_precision)\n",
    "        if macro_precision != 0:\n",
    "            macro_precision_scores.append(macro_precision)\n",
    "        if micro_recall != 0:\n",
    "            micro_recall_scores.append(micro_recall)\n",
    "        if macro_recall != 0:\n",
    "            macro_recall_scores.append(macro_recall)\n",
    "\n",
    "    # Calculate average precision and recall scores for micro and macro averages\n",
    "    return (\n",
    "        average(micro_precision_scores),\n",
    "        average(macro_precision_scores),\n",
    "        average(micro_recall_scores),\n",
    "        average(macro_recall_scores)\n",
    "    )\n",
    "\n",
    "\n",
    "def average(numeric_list):\n",
    "    return sum(numeric_list) / len(numeric_list)\n",
    "\n",
    "\n",
    "def print_result(\n",
    "    average_micro_precision,\n",
    "    average_macro_precision,\n",
    "    average_micro_recall, \n",
    "    average_macro_recall\n",
    "):\n",
    "    print(\"Average Micro Precision: {:.2f}\".format(average_micro_precision))\n",
    "    print(\"Average Macro Precision: {:.2f}\".format(average_macro_precision))\n",
    "    print(\"Average Micro Recall: {:.2f}\".format(average_micro_recall))\n",
    "    print(\"Average Macro Recall: {:.2f}\".format(average_macro_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Naive Bayes****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        default_naive_bayes_classifier,\n",
    "        four_fold,\n",
    "        dataframe_label_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Logistic Regression****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        default_logistic_regression_classifier,\n",
    "        four_fold, dataframe_onehot_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Train/test/evaluate the 2 models in cross-validation with modified parameters (#1)**\n",
    "\n",
    "Trying to change smoothing parameter `alpha` parameter for the Naive Bayes classifier.\n",
    "\n",
    "The smoothing parameter is used to handle the problem of zero probabilities.\n",
    "* In the context of Naive Bayes, it refers to the issue where a feature in the test data has a probability of zero for a particular class because that feature did not appear in the training data for that class, which can cause the entire predicted probability for that class to be zero.\n",
    "* To solve this problem, a small positive value (alpha) is added to the *count* of each feature when calculating the conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_naive_bayes_classifier_1 = CategoricalNB(alpha=0.3)\n",
    "print(\"Naive Bayes with alpha = 0.3:\")\n",
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        alpha_naive_bayes_classifier_1,\n",
    "        four_fold,\n",
    "        dataframe_label_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "print()\n",
    "alpha_naive_bayes_classifier_2 = CategoricalNB(alpha=0.7)\n",
    "print(\"Naive Bayes with alpha = 0.7:\")\n",
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        alpha_naive_bayes_classifier_2,\n",
    "        four_fold,\n",
    "        dataframe_label_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Train/test/evaluate the 2 models in cross-validation with modified parameters (#2)**\n",
    "\n",
    "Modify the different types of solver in the logistic regression classifier. We chose two solvers for this comparison: `newton-cholesky` and `liblinear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newton_logistic_regression_classifier = LogisticRegression(solver = \"newton-cholesky\")\n",
    "print(\"Newton-Cholesky Result:\")\n",
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        newton_logistic_regression_classifier,\n",
    "        four_fold,\n",
    "        dataframe_onehot_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liblinear_regression_classifier = LogisticRegression(solver = \"liblinear\")\n",
    "print(\"liblinear Result:\")\n",
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        liblinear_regression_classifier,\n",
    "        four_fold,\n",
    "        dataframe_onehot_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Train/test/evaluate the 2 models in cross-validation with modified parameters (#3)**\n",
    "\n",
    "Modify the tolerance parameter in the in the logistic regression classifier.\n",
    "\n",
    "The tolerance parameter determines the stopping criteria. The algorithm stops when the change in the loss function (or cost function) between iterations is smaller than the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tol in (1e-2, 1e-15):\n",
    "    tol_regression_classifer = LogisticRegression(tol=tol)\n",
    "    print(f\"Regression classifer with tol = {tol}:\")\n",
    "    print_result(\n",
    "        *train_and_evaluate(\n",
    "            tol_regression_classifer_1,\n",
    "            four_fold,\n",
    "            dataframe_onehot_feature,\n",
    "            dataframe_label_class[\"class\"]\n",
    "        )\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Train/test/evaluate the 2 models in cross-validation with modified parameters (#4)**\n",
    "\n",
    "Modify the `fit_prior` parameter in the in the Naive Bayes classifier.\n",
    "\n",
    "By default, the classifier will calculate the prior probabilities of each class based on the relative frequency of each class in the training data.\n",
    "\n",
    "When `fit_prior` is set to `False`, the classifier will assume a uniform prior, meaning that it treats all classes equally likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_naive_bayes_classifier = CategoricalNB(fit_prior=False)\n",
    "print(\"Result of Naive Bayes with uniform prior:\")\n",
    "print_result(\n",
    "    *train_and_evaluate(\n",
    "        new_naive_bayes_classifier,\n",
    "        four_fold,\n",
    "        dataframe_label_feature,\n",
    "        dataframe_label_class[\"class\"]\n",
    "    )\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Analyze the obtained results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "name_list = [\"Default Naive Bayes\", \"Naive Bayes (alpha = 0.3)\", \"Naive Bayes (alpha = 0.7)\",\n",
    "            \"Default Logistic Regression\", \"Newton-Cholesky Logistic Regression\", \"liblinear Logistic Regression\"]\n",
    "\n",
    "x_label = [\"Micro Precision\", \"Macro Precision\", \"Micro Recall\", \"Macro Recall\"]\n",
    "\n",
    "result_list = []\n",
    "result_list.append(train_and_evaluate(default_naive_bayes_classifier, four_fold, dataframe_label_feature, dataframe_label_class[\"class\"]))\n",
    "result_list.append(train_and_evaluate(default_logistic_regression_classifier, four_fold, dataframe_onehot_feature, dataframe_label_class[\"class\"]))\n",
    "result_list.append(train_and_evaluate(alpha_naive_bayes_classifier_1, four_fold, dataframe_label_feature, dataframe_label_class[\"class\"]))\n",
    "result_list.append(train_and_evaluate(alpha_naive_bayes_classifier_2, four_fold, dataframe_label_feature, dataframe_label_class[\"class\"]))\n",
    "result_list.append(train_and_evaluate(newton_logistic_regression_classifier, four_fold, dataframe_onehot_feature, dataframe_label_class[\"class\"]))\n",
    "result_list.append(train_and_evaluate(liblinear_regression_classifier, four_fold, dataframe_onehot_feature, dataframe_label_class[\"class\"]))\n",
    "\n",
    "width = 0.3\n",
    "x_list = [0.2, 2.8, 5.4, 8]\n",
    "plot.figure(figsize=(12, 4))\n",
    "for i in range(6):\n",
    "    plot.bar(x_list, result_list[i], width=0.3, tick_label = x_label, label=name_list[i]) if i==2 else plot.bar(x_list, result_list[i], width=0.3, label=name_list[i])\n",
    "\n",
    "    for k in range(len(x_list)):\n",
    "        x_list[k] = x_list[k] + width\n",
    "plot.subplots_adjust(right=2, top=2)\n",
    "plot.xlabel(\"Model Name\")\n",
    "plot.ylabel(\"Results\")\n",
    "plot.legend()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ikmq-si_23Y"
   },
   "source": [
    "**13. Conclusion**\n",
    "\n",
    "In this empirical study, we explored a classification task aiming to predict class labels for instances using two models: Logistic Regression and Naive Bayes. Through feature analysis and engineering, we ensured the relevance of attributes for the classification task.\n",
    "\n",
    "By employing 4-fold cross-validation, we evaluated the models using precision and recall measures by comparing both micro and macro averages. Through some parameter modifications in two experiments for each model, we explored the impact on model performance.\n",
    "\n",
    "The results revealed nuanced differences in model performance based on parameter variations. These differences, observed in precision and recall metrics, were analyzed with a comparative plot, from which we can see, the Naive Bayes model with alpha value set to 0.3 renders the most optimal result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41s8gvCNABDy"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtbOgI1q_9a0"
   },
   "source": [
    "**14. References**\n",
    "\n",
    "[1]\tF. Pedregosa et al., ‘Scikit-learn: Machine Learning in Python’, Journal of Machine Learning Research, vol. 12, pp. 2825–2830, 2011.\n",
    "\n",
    "[2]\tL. Buitinck et al., ‘API design for machine learning software: experiences from the scikit-learn project’, in ECML PKDD Workshop: Languages for Data Mining and Machine Learning, 2013, pp. 108–122.\n",
    "References\n",
    "\n",
    "[3] M. Bohanec, 'Car Evaluation'. UCI Machine Learning Repository, 1988. doi:10.24432/C5JP48"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
