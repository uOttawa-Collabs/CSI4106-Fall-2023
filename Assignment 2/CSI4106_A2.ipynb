{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPeulvp-meob"
   },
   "source": [
    "**ASSIGNMENT 2 - Classification Empirical Study: Naïve Bayes vs Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2Eeke4Z_EkW"
   },
   "source": [
    "**1. Group Description**\n",
    "\n",
    "Group Number: 10\n",
    "\n",
    "Member Name 1: Xiaoxuan Wang\n",
    "\n",
    "Member Student Number 1: 300133594\n",
    "\n",
    "Member Name 2: Victor Li\n",
    "\n",
    "Member Student Number 2: 300146133"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZTWy1qN2BzY"
   },
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmP1buROhaOx"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8vwHE0G_iOG"
   },
   "source": [
    "**2. Dataset**\n",
    "\n",
    "Chosen dataset: Car dataset\n",
    "\n",
    "The dataset is coming from [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/).\n",
    "It can be retrieved by following [this link](https://archive.ics.uci.edu/dataset/19/car+evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNJyoeCz00Kr"
   },
   "source": [
    "**Read Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrhpM-HwhaOy"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/uOttawa-Collabs/CSI4106-Fall-2023/master/Assignment%202/Car/car.data\"\n",
    "dataframe = pandas.read_csv(url)\n",
    "dataframe.columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ER3-7di7ufy"
   },
   "source": [
    "**3. Familiarize with the classification task and the dataset**\n",
    "\n",
    "***Objective***\n",
    "\n",
    "The objective of this study is to develop a classification model to evaluate cars based on their configurations and parameters. The dataset comprises six discrete (categorical) feature variables: buying price, maintenance price, number of doors, capacity in terms of persons, the size of the luggage boot, and estimated safety of the car. The target variable is the evaluation of the car, categorized into four classes: unacceptable, acceptable, good, and very good.\n",
    "\n",
    "***Applications***\n",
    "\n",
    "1. May assist customers to make informed decisions based on their preferences and constraints, offering valuable insights.\n",
    "2. May assist car dealership to help assist potential buyers in finding cars that align with their requirements, thereby enhancing customer satisfaction and loyalty.\n",
    "\n",
    "***Dataset Characteristics Analysis***\n",
    "\n",
    "****Features****\n",
    "\n",
    "The dataset used for this study contains information on the following six feature variables:\n",
    "* Buying Price (`buying`): Indicates the price range at which the car was purchased.\n",
    "    * Possible values: `vhigh`, `high`, `med`, `low`.\n",
    "* Maintenance Price (`maint`): Represents the maintenance cost of the car.\n",
    "    * Possible values: `vhigh`, `high`, `med`, `low`.\n",
    "* Number of Doors (`doors`): Denotes the number of doors the car has.\n",
    "    * Possible values: `2`, `3`, `4`, `5more`.\n",
    "* Capacity (`persons`): Indicates the maximum number of persons the car can accommodate.\n",
    "    * Possible values: `2`, `4`, `more`.\n",
    "* Luggage Boot Size (`lug_boot`): Represents the size of the luggage boot in the car.\n",
    "    * Possible values: `small`, `med`, `big`.\n",
    "* Estimated Safety (`safety`): Provides an estimation of the safety level of the car.\n",
    "    * Possible values: `low`, `med`, `high`.\n",
    "\n",
    "****Classes****\n",
    "\n",
    "The target variable is Car Evaluation (`class`), which classifies cars into four categories:\n",
    "unacceptable (`unacc`), acceptable (`acc`), good (`good`), and very good (`vgood`).\n",
    "These classes serve as the basis for evaluating the overall desirability of a car.\n",
    "\n",
    "****Training Examples****\n",
    "\n",
    "The dataset contains 1728 training samples in total. No samples have missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Brainstorm about the attributes**\n",
    "\n",
    "* In the automotive sales market, various factors significantly influence purchasing decisions. Aside from intrinsic attributes provided in the dataset, **features**, **second-hand price**, **power**, **brand**, **color**, and **after-sale service** are essential as well.\n",
    "\n",
    "  Among the provided attributes in the dataset, the data related to the **number of doors** appears to be less useful, given its correlation with a car's **capacity**. In typical scenarios, a capacity of 2 necessitates a minimum of 2 doors, while a capacity of 4 often results in 4 doors, with a minimum of 2. The relationship between a car's capacity and its doors is evident: larger capacities generally correspond to a higher number of doors. Although it is conceivable that unconventional door numbers, such as odd numbers, might intrigue some customers, it is unlikely that this singular feature significantly influences purchase decisions.\n",
    "\n",
    "* Based on the diagrams below, it is apparent that each feature exhibits uniformity across all values, mitigating potential biases during model training. Given that all features in this dataset represent discrete values (for instance, the number of persons cannot be fractional), the method of attribute normalization appears inappropriate for this specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "\n",
    "buying_dict = {\"low\": 0, \"med\": 0, \"high\": 0, \"vhigh\": 0}\n",
    "maint_dict = {\"low\": 0, \"med\": 0, \"high\": 0, \"vhigh\": 0}\n",
    "door_dict = {\"2\": 0, \"3\": 0, \"4\": 0, \"5more\": 0}\n",
    "persons_dict = {\"2\": 0, \"4\": 0, \"more\": 0}\n",
    "lug_dict = {\"small\": 0, \"med\": 0, \"big\": 0}\n",
    "safety_dict = {\"low\": 0, \"med\": 0, \"high\": 0}\n",
    "\n",
    "def analyze_data(dataframe, prop, dic):\n",
    "    data = dataframe[prop]\n",
    "    for row in data:\n",
    "        dic[row] += 1\n",
    "    generate_diagram(dic, prop)\n",
    "\n",
    "def generate_diagram(dic: dict, name):\n",
    "    print(dic)\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i in dic.keys():\n",
    "        x_list.append(i)\n",
    "        y_list.append(dic[i])\n",
    "    plot.bar(x_list, y_list)\n",
    "    plot.title(\"Analysis of \" + \" Feature \" + name)\n",
    "    plot.xlabel(\"name\")\n",
    "    plot.ylabel(\"number\")\n",
    "    plot.show()\n",
    "\n",
    "\n",
    "analyze_data(dataframe, \"buying\", buying_dict)\n",
    "analyze_data(dataframe, \"maint\", maint_dict)\n",
    "analyze_data(dataframe, \"doors\", door_dict)\n",
    "analyze_data(dataframe, \"persons\", persons_dict)\n",
    "analyze_data(dataframe, \"lug_boot\", lug_dict)\n",
    "analyze_data(dataframe, \"safety\", safety_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Encode the features**\n",
    "\n",
    "* The data source that was chosen is using discrete variables for all features. It natively fits into the Categorical Naive Bayes Model (`CategoricalNB`). We just need to label them with integers.\n",
    "* For Logistic Regression, one-hot encoding enables the conversion to continuous variables for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "feature_columns = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\"]\n",
    "class_column = \"class\"\n",
    "\n",
    "# Performing label encoding for features\n",
    "dataframe_label_feature = pandas.DataFrame().reindex_like(dataframe[feature_columns])\n",
    "label_encoder_dict = {}\n",
    "for column in feature_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    dataframe_label_feature[column] = label_encoder.fit_transform(dataframe[column])\n",
    "    label_encoder_dict[column] = label_encoder\n",
    "\n",
    "# Performing one-hot encoding for features\n",
    "onehot_encoder_feature = OneHotEncoder(sparse_output=False)\n",
    "matrix_onehot_feature = onehot_encoder_feature.fit_transform(dataframe[feature_columns])\n",
    "dataframe_onehot_feature = pandas.DataFrame(matrix_onehot_feature, columns=onehot_encoder_feature.get_feature_names_out())\n",
    "\n",
    "# Performing label encoding for classes\n",
    "label_encoder_class = LabelEncoder()\n",
    "vector_label_class = label_encoder_class.fit_transform(dataframe[class_column])\n",
    "dataframe_label_class = pandas.DataFrame(vector_label_class, columns=[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Define 2 models using default parameters**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "naive_bayes_classifier = CategoricalNB()\n",
    "logistic_regression_classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Train/test/evaluate the 2 models in cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initialize KFold Cross Validator***\n",
    "\n",
    "Here we are initializing the `KFold` validator. Explanation of parameters:\n",
    "* `n_splits=4` means we are using 4-fold validation.\n",
    "* `shuffle=True` means data will be shuffled before spliting to batches.\n",
    "* `random_state` is the random seed used for shuffling. Here we are using a fixed number to keep reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "four_fold = KFold(n_splits=4, shuffle=True, random_state=4106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Training and Evaluating the Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Utility Functions****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "def train_and_evaluate(model, validator, dataframe_training, series_validating):\n",
    "    micro_precision_scores = []\n",
    "    macro_precision_scores = []\n",
    "    micro_recall_scores = []\n",
    "    macro_recall_scores = []\n",
    "    \n",
    "    X = dataframe_training\n",
    "    y = series_validating\n",
    "    \n",
    "    for train_index, test_index in validator.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        # Make predictions ŷ\n",
    "        y_hat = model.predict(X_test)\n",
    "        \n",
    "        # Calculate precision and recall for micro and macro averages\n",
    "        micro_precision = precision_score(y_test, y_hat, average=\"micro\")\n",
    "        macro_precision = precision_score(y_test, y_hat, average=\"macro\")\n",
    "        micro_recall = recall_score(y_test, y_hat, average=\"micro\")\n",
    "        macro_recall = recall_score(y_test, y_hat, average=\"macro\")\n",
    "    \n",
    "        # Append scores to lists\n",
    "        micro_precision_scores.append(micro_precision)\n",
    "        macro_precision_scores.append(macro_precision)\n",
    "        micro_recall_scores.append(micro_recall)\n",
    "        macro_recall_scores.append(macro_recall)\n",
    "    \n",
    "    # Calculate average precision and recall scores for micro and macro averages\n",
    "    average_micro_precision = sum(micro_precision_scores) / len(micro_precision_scores)\n",
    "    average_macro_precision = sum(macro_precision_scores) / len(macro_precision_scores)\n",
    "    average_micro_recall = sum(micro_recall_scores) / len(micro_recall_scores)\n",
    "    average_macro_recall = sum(macro_recall_scores) / len(macro_recall_scores)\n",
    "    \n",
    "    print(\"Average Micro Precision: {:.2f}\".format(average_micro_precision))\n",
    "    print(\"Average Macro Precision: {:.2f}\".format(average_macro_precision))\n",
    "    print(\"Average Micro Recall: {:.2f}\".format(average_micro_recall))\n",
    "    print(\"Average Macro Recall: {:.2f}\".format(average_macro_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Naive Bayes****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(naive_bayes_classifier, four_fold, dataframe_label_feature, dataframe_label_class[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Logistic Regression****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(logistic_regression_classifier, four_fold, dataframe_onehot_feature, dataframe_label_class[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Train/test/evaluate the 2 models in cross-validation with modified parameters (#1)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Train/test/evaluate the 2 models in cross-validation with modified parameters (#2)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Analyze the obtained results**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp7TpkAIUe"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ikmq-si_23Y"
   },
   "source": [
    "**11. Conclusion**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41s8gvCNABDy"
   },
   "source": [
    "--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtbOgI1q_9a0"
   },
   "source": [
    "**12. References**\n",
    "\n",
    "[1] M. Bohanec, 'Car Evaluation'. UCI Machine Learning Repository, 1988. doi:10.24432/C5JP48"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
